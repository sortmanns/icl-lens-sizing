{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={\"figure.figsize\": (16, 9.)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", 120)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "from icl_lens_sizing.preprocessing.preprocessing import prepare_training_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and prepare ICL data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = \"/Users/sortmanns/git/work/icl-lens-sizing/data/icl_data_2023-07-09.csv\"\n",
    "df = pd.read_csv(path, sep=\";\", decimal=',')\n",
    "features = ['implantat_size', 'AtA', 'ACW', 'ARtAR_LR', 'StS', 'CBID',\n",
    "       'WtW_MS-39', 'Sphaere']\n",
    "# cbid_ratio = (lambda row: row['CBID'] / row['CBID_LR'])\n",
    "custom_features = None # {'spherical_equivalent': (lambda row: row['Sphaere']-0.5*row['Zylinder'])}\n",
    "feature_df, target_df, feature_mapping = prepare_training_data(df=df, target=\"Lens-ICPL-Distance\", features=features,custom_features=custom_features)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(feature_df, target_df, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 21.54434690031882\n",
      "Mean Absolute Error: 121.19245834156754\n"
     ]
    }
   ],
   "source": [
    "# Define a range of alpha values\n",
    "alphas = np.logspace(-4, 2, 10)  # Example range\n",
    "\n",
    "# Create a dictionary of hyperparameters to search\n",
    "param_grid = {'estimator__alpha': alphas}\n",
    "\n",
    "# Create a Lasso regressor\n",
    "model_lasso = Lasso()\n",
    "standard_scaler = StandardScaler()\n",
    "pipeline = Pipeline([('transformer', standard_scaler), ('estimator', model_lasso)])\n",
    "# Create GridSearchCV or RandomizedSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "# For Randomized Search\n",
    "# random_search = RandomizedSearchCV(lasso, param_distributions=param_grid, cv=5, n_iter=10, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "# For Randomized Search\n",
    "# random_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_['estimator__alpha']\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "best_lasso = Lasso(alpha=best_alpha)\n",
    "best_lasso.fit(X_train, y_train)\n",
    "y_pred = best_lasso.predict(X_validation)\n",
    "\n",
    "mae = mean_absolute_error(y_validation, y_pred)\n",
    "print(\"Mean Absolute Error:\", mae)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Try elastic net on full feature set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1: Coefficient = -20.9627, P-value = 0.8055\n",
      "Feature 2: Coefficient = -13.1507, P-value = 0.8492\n",
      "Feature 3: Coefficient = 17.8742, P-value = 0.7650\n",
      "Feature 4: Coefficient = -0.5220, P-value = 0.0007\n",
      "Feature 5: Coefficient = -33.4809, P-value = 0.4659\n",
      "Feature 6: Coefficient = -52.0218, P-value = 0.2766\n",
      "Feature 7: Coefficient = -14.0416, P-value = 0.8665\n",
      "Feature 8: Coefficient = -0.3682, P-value = 0.9462\n"
     ]
    }
   ],
   "source": [
    "features = ['implantat_size', 'alter', 'ACD', 'ACA_nasal', 'ACA_temporal', 'AtA', 'ACW',\n",
    "            'ARtAR_LR', 'StS', 'StS_LR', 'CBID', 'CBID_LR', 'mPupil', 'WtW_MS-39', 'Sphaere', 'Zylinder']\n",
    "cbid_ratio = (lambda row: row['CBID'] / row['CBID_LR'])\n",
    "ac_ratio = (lambda row: row['ACW'] / row['ACD'])\n",
    "sts_ratio = (lambda row: row['StS'] / row['StS_LR'])\n",
    "ata_ratio = (lambda row: row['AtA'] / row['ARtAR_LR'])\n",
    "spherical_equivalent = (lambda row: row['Sphaere']-0.5*row['Zylinder'])\n",
    "custom_features = {'spherical_equivalent': spherical_equivalent, 'cbid_ratio': cbid_ratio,\n",
    "                   'ac_ratio':ac_ratio, 'sts_ratio':sts_ratio, 'ata_ratio':ata_ratio}\n",
    "# Create an Elastic Net regressor\n",
    "alpha = 0.5  # Regularization strength (mixing parameter)\n",
    "l1_ratio = 0.5  # Mixing parameter between L1 and L2 regularization\n",
    "enet = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "\n",
    "# Fit the model on the training data\n",
    "enet.fit(X_train, y_train)\n",
    "\n",
    "# Get the coefficients and intercept\n",
    "coefficients = enet.coef_\n",
    "intercept = enet.intercept_\n",
    "\n",
    "# Obtain p-values using statistical methods (e.g., t-tests)\n",
    "from scipy import stats\n",
    "\n",
    "n_samples, n_features = X_train.shape\n",
    "degrees_of_freedom = n_samples - n_features - 1\n",
    "t_scores = coefficients / (np.std(y_train) / np.sqrt(np.sum((X_train - np.mean(X_train, axis=0)) ** 2, axis=0)))\n",
    "p_values = 2 * (1 - stats.t.cdf(np.abs(t_scores), df=degrees_of_freedom))\n",
    "\n",
    "# Print coefficients and p-values\n",
    "for i, (coef, p_value) in enumerate(zip(coefficients, p_values)):\n",
    "    print(f\"Feature {i + 1}: Coefficient = {coef:.4f}, P-value = {p_value:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['implantat_size', 'AtA', 'ACW', 'ARtAR_LR', 'StS', 'CBID',\n       'WtW_MS-39', 'Sphaere'], dtype=object)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet.feature_names_in_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'enet__alpha': 0.1, 'enet__l1_ratio': 0.5}\n",
      "Test MAE: 122.70122559761973\n",
      "Cross-Validation MAE Scores: [101.90645666  81.07458344 111.62651897 186.04806047 160.37383158]\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with standardization and Elastic Net regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('enet', ElasticNet())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for Elastic Net\n",
    "param_grid = {\n",
    "    'enet__alpha': [0.1, 0.5, 1.0],\n",
    "    'enet__l1_ratio': [0.2, 0.5, 0.8]\n",
    "}\n",
    "\n",
    "# Create a custom scorer using mean_absolute_error\n",
    "mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "\n",
    "# Perform cross-validation with the pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=mae_scorer)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate on the test set using the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_validation)\n",
    "test_mae = mean_absolute_error(y_validation, y_pred)\n",
    "print(\"Test MAE:\", test_mae)\n",
    "\n",
    "# Alternatively, you can directly use cross_val_score\n",
    "cross_val_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=mae_scorer)\n",
    "print(\"Cross-Validation MAE Scores:\", -cross_val_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}